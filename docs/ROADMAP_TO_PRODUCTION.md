# üõ£Ô∏è Roadmap to Production: Risk Scoring Engine

Este documento redefine el camino hacia la maestr√≠a en MLOps, enfoc√°ndose en la infraestructura s√≥lida, la simulaci√≥n realista y el monitoreo continuo, evitando distracciones prematuras (como agentes aut√≥nomos) hasta dominar los fundamentos.

## üéØ Meta Final

Tener un sistema que procese datos reales (Kaggle), se despliegue autom√°ticamente (CI/CD), viva en contenedores optimizados (Docker) y tenga un dashboard de monitoreo en tiempo real que simule la operaci√≥n diaria de un banco.

---

## üèóÔ∏è FASE 1: Fundamentos de Infraestructura (Docker & CI/CD)
>
> **Estado:** üöß En Progreso
> **Objetivo:** "Si funciona en mi m√°quina, funciona en la nube".

### 1.1. Docker Pro (Infraestructura Inmutable)

Ya tenemos un `Dockerfile` b√°sico, pero para producci√≥n real necesitamos:

- **Optimization:** Reducir el tama√±o de la imagen (de ~1GB a ~200MB) usando *Multi-stage builds*.
- **Security:** Gesti√≥n segura de secretos (no hardcodeados).
- **Entendimiento Profundo:** Diferenciar entre construir la imagen (`build`) y correr el contenedor (`run`), y c√≥mo exponer puertos correctamente.

### 1.2. GitHub Actions (El Robot Guardi√°n)

Ya creamos el archivo YAML, pero necesitamos "sentir el dolor" para aprender:

- **Simulaci√≥n de Fallo:** Introducir un error intencional (ej. data leakage) y ver c√≥mo GitHub Actions bloquea el despliegue.
- **Continuous Integration (CI):** Entender el flujo `Push` -> `Test` -> `Build`.

---

## üëÅÔ∏è FASE 2: Observabilidad y Monitoreo (Drift)
>
> **Estado:** üìÖ Pendiente
> **Objetivo:** "¬øMi modelo sigue siendo inteligente o se ha vuelto tonto?"

### 2.1. Conceptos de Drift

Entender que los datos cambian con el tiempo (ej. inflaci√≥n afecta ingresos).

- **Data Drift:** Cambios en la distribuci√≥n de las variables de entrada (`AMT_INCOME`).
- **Concept Drift:** Cambios en la relaci√≥n entre variables y el target (la definici√≥n de "moroso" cambia).

### 2.2. Estrategia de Monitoreo

Dise√±ar un sistema que alerte si:

- El % de nulos sube repentinamente.
- La distribuci√≥n de predicciones cambia dr√°sticamente.

---

## üè¶ FASE 3: La Gran Simulaci√≥n (Real-World Emulation)
>
> **Estado:** üìÖ Pendiente
> **Objetivo:** Simular un entorno bancario vivo.

### 3.1. Ingesta de Datos Reales

- Cargar el dataset completo de Kaggle (`application_train.csv` ~300k filas).
- Adaptar `make_dataset.py` para manejar archivos grandes sin explotar la memoria.

### 3.2. Estrategia de "Viaje en el Tiempo"

Dividir los 300k datos en:

- **Historia (Training):** Los primeros 280,000 clientes (ordenados por fecha si fuera posible, o aleatorio).
- **Futuro (Inference):** Los √∫ltimos 20,000 clientes, reservados para simular la llegada de nuevos solicitantes d√≠a a d√≠a.

### 3.3. Simulador de Tr√°fico (El "Cliente")

Crear un script en Python que act√∫e como el sistema del banco:

- Lee los 20k datos reservados.
- Env√≠a peticiones `POST /predict` a nuestra API Dockerizada cada pocos segundos.
- Simula picos de tr√°fico.

### 3.4. Dashboard de Control (Streamlit)

Construir un centro de mando visual que consuma los resultados de la API y muestre:

- **Aprobaciones vs Rechazos** en tiempo real.
- **Histograma de Riesgo** actualizado al segundo.
- **Alertas de Calidad** (Drift detectado).

---

## üö´ Fuera del Alcance (Por ahora)

- **Agentes Aut√≥nomos (Deep Research/Coding Agents):** Distracci√≥n. Primero debemos construir el sistema que el agente eventualmente operar√≠a.
- **Cloud Deploy (GCP/AWS):** Primero dominaremos Docker localmente. Desplegar una imagen Docker optima es trivial si la imagen est√° bien hecha.

---

## üìù Siguientes Pasos Inmediatos

1. **Terminar Fase 1:** Optimizar Docker y validar GitHub Actions.
2. **Conseguir Datos:** Descargar dataset de Kaggle.
3. **Iniciar Fase 3:** Construir el simulador.
